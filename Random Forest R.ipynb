{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>gender</th><th scope=col>race.ethnicity</th><th scope=col>parental.level.of.education</th><th scope=col>lunch</th><th scope=col>test.preparation.course</th><th scope=col>reading.score</th><th scope=col>writing.score</th><th scope=col>math.score</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>female            </td><td>group B           </td><td>bachelor's degree </td><td>standard          </td><td>none              </td><td>72                </td><td>74                </td><td>72                </td></tr>\n",
       "\t<tr><td>female            </td><td>group C           </td><td>some college      </td><td>standard          </td><td>completed         </td><td>90                </td><td>88                </td><td>69                </td></tr>\n",
       "\t<tr><td>female            </td><td>group B           </td><td>master's degree   </td><td>standard          </td><td>none              </td><td>95                </td><td>93                </td><td>90                </td></tr>\n",
       "\t<tr><td>male              </td><td>group A           </td><td>associate's degree</td><td>free/reduced      </td><td>none              </td><td>57                </td><td>44                </td><td>47                </td></tr>\n",
       "\t<tr><td>male              </td><td>group C           </td><td>some college      </td><td>standard          </td><td>none              </td><td>78                </td><td>75                </td><td>76                </td></tr>\n",
       "\t<tr><td>female            </td><td>group B           </td><td>associate's degree</td><td>standard          </td><td>none              </td><td>83                </td><td>78                </td><td>71                </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllll}\n",
       " gender & race.ethnicity & parental.level.of.education & lunch & test.preparation.course & reading.score & writing.score & math.score\\\\\n",
       "\\hline\n",
       "\t female             & group B            & bachelor's degree  & standard           & none               & 72                 & 74                 & 72                \\\\\n",
       "\t female             & group C            & some college       & standard           & completed          & 90                 & 88                 & 69                \\\\\n",
       "\t female             & group B            & master's degree    & standard           & none               & 95                 & 93                 & 90                \\\\\n",
       "\t male               & group A            & associate's degree & free/reduced       & none               & 57                 & 44                 & 47                \\\\\n",
       "\t male               & group C            & some college       & standard           & none               & 78                 & 75                 & 76                \\\\\n",
       "\t female             & group B            & associate's degree & standard           & none               & 83                 & 78                 & 71                \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "gender | race.ethnicity | parental.level.of.education | lunch | test.preparation.course | reading.score | writing.score | math.score | \n",
       "|---|---|---|---|---|---|\n",
       "| female             | group B            | bachelor's degree  | standard           | none               | 72                 | 74                 | 72                 | \n",
       "| female             | group C            | some college       | standard           | completed          | 90                 | 88                 | 69                 | \n",
       "| female             | group B            | master's degree    | standard           | none               | 95                 | 93                 | 90                 | \n",
       "| male               | group A            | associate's degree | free/reduced       | none               | 57                 | 44                 | 47                 | \n",
       "| male               | group C            | some college       | standard           | none               | 78                 | 75                 | 76                 | \n",
       "| female             | group B            | associate's degree | standard           | none               | 83                 | 78                 | 71                 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  gender race.ethnicity parental.level.of.education lunch       \n",
       "1 female group B        bachelor's degree           standard    \n",
       "2 female group C        some college                standard    \n",
       "3 female group B        master's degree             standard    \n",
       "4 male   group A        associate's degree          free/reduced\n",
       "5 male   group C        some college                standard    \n",
       "6 female group B        associate's degree          standard    \n",
       "  test.preparation.course reading.score writing.score math.score\n",
       "1 none                    72            74            72        \n",
       "2 completed               90            88            69        \n",
       "3 none                    95            93            90        \n",
       "4 none                    57            44            47        \n",
       "5 none                    78            75            76        \n",
       "6 none                    83            78            71        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Visualization\n",
    "library(ggplot2)\n",
    "\n",
    "# Random Forest\n",
    "library(randomForest)\n",
    "require(caTools)\n",
    "\n",
    "# We change our working directory...\n",
    "setwd('C:\\\\Users\\\\...\\\\Downloads\\\\students-performance-in-exams')\n",
    "\n",
    "# We pass our data into an array...\n",
    "df <- read.csv('StudentsPerformance.csv')\n",
    "df <- df[c(1,2,3,4,5,7,8,6)]\n",
    "data <- df\n",
    "\n",
    "# Let's see what we have here...\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] female male  \n",
      "Levels: female male\n",
      "[1] group B group C group A group D group E\n",
      "Levels: group A group B group C group D group E\n",
      "[1] bachelor's degree  some college       master's degree    associate's degree\n",
      "[5] high school        some high school  \n",
      "6 Levels: associate's degree bachelor's degree high school ... some high school\n",
      "[1] standard     free/reduced\n",
      "Levels: free/reduced standard\n",
      "[1] none      completed\n",
      "Levels: completed none\n"
     ]
    }
   ],
   "source": [
    "# It looks like our data does not have too mnay features...\n",
    "# Also, the features all look categorical, but, currently in string form...\n",
    "# We will use integers to clean our features for the algorthim.\n",
    "# We get the unique values in each column for integer-based categories.\n",
    "for (column in 1:5) {\n",
    "    print(unique(df[,column]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We clean the gender column...\n",
    "clean_gender <- function(x) {\n",
    "    if ( x == 'male') {\n",
    "        x = 0\n",
    "    }\n",
    "    \n",
    "    else {\n",
    "        x = 1\n",
    "    }\n",
    "        \n",
    "}\n",
    "df[,1] = sapply(df[,1], clean_gender)\n",
    "\n",
    "# We clean the race.ethnicity column...\n",
    "clean_ethnicity <- function(x) {\n",
    "    if ( x == 'group A') {\n",
    "        x = 0\n",
    "    } else if ( x == 'group B') {\n",
    "        x = 1\n",
    "    } else if ( x == 'group C') {\n",
    "        x = 2\n",
    "    } else if ( x == 'group D') {\n",
    "        x = 3\n",
    "    } else {\n",
    "        x = 4\n",
    "    }\n",
    "}\n",
    "\n",
    "df[,2] = sapply(df[,2], clean_ethnicity)\n",
    "\n",
    "# We clean the parent.level.of.education column...\n",
    "clean_education <- function(x) {\n",
    "    if ( x == \"bachelor's degree\") {\n",
    "        x = 0 \n",
    "    } else if ( x == \"some college\") {\n",
    "        x = 1\n",
    "    } else if ( x == \"master's degree\") {\n",
    "        x = 2\n",
    "    } else if ( x == \"associate's degree\") {\n",
    "        x = 3\n",
    "    } else if ( x == \"high school\") {\n",
    "        x = 4\n",
    "    } else {\n",
    "        x = 5\n",
    "    }\n",
    "}\n",
    "\n",
    "df[,3] = sapply(df[,3], clean_education)\n",
    "\n",
    "# We clean the lunch column...\n",
    "clean_lunch <- function(x) {\n",
    "    if ( x == 'standard') {\n",
    "        x = 0\n",
    "    } else {\n",
    "        x = 1\n",
    "    }\n",
    "}\n",
    "\n",
    "df[,4] = sapply(df[,4], clean_lunch)\n",
    "\n",
    "# We clean the test.preparation.course column...\n",
    "clean_prep <- function(x) {\n",
    "    if ( x == 'completed') {\n",
    "        x = 0\n",
    "    } else {\n",
    "        x = 1\n",
    "    }\n",
    "}\n",
    "\n",
    "df[,5] = sapply(df[,5], clean_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>gender</th><th scope=col>race.ethnicity</th><th scope=col>parental.level.of.education</th><th scope=col>lunch</th><th scope=col>test.preparation.course</th><th scope=col>reading.score</th><th scope=col>writing.score</th><th scope=col>math.score</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1 </td><td>1 </td><td>0 </td><td>0 </td><td>1 </td><td>72</td><td>74</td><td>72</td></tr>\n",
       "\t<tr><td>1 </td><td>2 </td><td>1 </td><td>0 </td><td>0 </td><td>90</td><td>88</td><td>69</td></tr>\n",
       "\t<tr><td>1 </td><td>1 </td><td>2 </td><td>0 </td><td>1 </td><td>95</td><td>93</td><td>90</td></tr>\n",
       "\t<tr><td>0 </td><td>0 </td><td>3 </td><td>1 </td><td>1 </td><td>57</td><td>44</td><td>47</td></tr>\n",
       "\t<tr><td>0 </td><td>2 </td><td>1 </td><td>0 </td><td>1 </td><td>78</td><td>75</td><td>76</td></tr>\n",
       "\t<tr><td>1 </td><td>1 </td><td>3 </td><td>0 </td><td>1 </td><td>83</td><td>78</td><td>71</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllll}\n",
       " gender & race.ethnicity & parental.level.of.education & lunch & test.preparation.course & reading.score & writing.score & math.score\\\\\n",
       "\\hline\n",
       "\t 1  & 1  & 0  & 0  & 1  & 72 & 74 & 72\\\\\n",
       "\t 1  & 2  & 1  & 0  & 0  & 90 & 88 & 69\\\\\n",
       "\t 1  & 1  & 2  & 0  & 1  & 95 & 93 & 90\\\\\n",
       "\t 0  & 0  & 3  & 1  & 1  & 57 & 44 & 47\\\\\n",
       "\t 0  & 2  & 1  & 0  & 1  & 78 & 75 & 76\\\\\n",
       "\t 1  & 1  & 3  & 0  & 1  & 83 & 78 & 71\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "gender | race.ethnicity | parental.level.of.education | lunch | test.preparation.course | reading.score | writing.score | math.score | \n",
       "|---|---|---|---|---|---|\n",
       "| 1  | 1  | 0  | 0  | 1  | 72 | 74 | 72 | \n",
       "| 1  | 2  | 1  | 0  | 0  | 90 | 88 | 69 | \n",
       "| 1  | 1  | 2  | 0  | 1  | 95 | 93 | 90 | \n",
       "| 0  | 0  | 3  | 1  | 1  | 57 | 44 | 47 | \n",
       "| 0  | 2  | 1  | 0  | 1  | 78 | 75 | 76 | \n",
       "| 1  | 1  | 3  | 0  | 1  | 83 | 78 | 71 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  gender race.ethnicity parental.level.of.education lunch\n",
       "1 1      1              0                           0    \n",
       "2 1      2              1                           0    \n",
       "3 1      1              2                           0    \n",
       "4 0      0              3                           1    \n",
       "5 0      2              1                           0    \n",
       "6 1      1              3                           0    \n",
       "  test.preparation.course reading.score writing.score math.score\n",
       "1 1                       72            74            72        \n",
       "2 0                       90            88            69        \n",
       "3 1                       95            93            90        \n",
       "4 1                       57            44            47        \n",
       "5 1                       78            75            76        \n",
       "6 1                       83            78            71        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We spot-check that the integer-based categories have successfully updated...\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>gender</th><th scope=col>race.ethnicity</th><th scope=col>parental.level.of.education</th><th scope=col>lunch</th><th scope=col>test.preparation.course</th><th scope=col>reading.score</th><th scope=col>writing.score</th><th scope=col>math.score</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>gender</th><td> 1.000000000</td><td> 0.001501924</td><td>-0.02838346 </td><td> 0.02137167 </td><td> 0.006027952</td><td> 0.2443126  </td><td> 0.3012249  </td><td>-0.1679822  </td></tr>\n",
       "\t<tr><th scope=row>race.ethnicity</th><td> 0.001501924</td><td> 1.000000000</td><td>-0.08048602 </td><td>-0.04656259 </td><td>-0.017508038</td><td> 0.1452526  </td><td> 0.1656905  </td><td> 0.2164154  </td></tr>\n",
       "\t<tr><th scope=row>parental.level.of.education</th><td>-0.028383460</td><td>-0.080486016</td><td> 1.00000000 </td><td>-0.01437793 </td><td>-0.011557512</td><td>-0.1434293  </td><td>-0.1923381  </td><td>-0.1392356  </td></tr>\n",
       "\t<tr><th scope=row>lunch</th><td> 0.021371670</td><td>-0.046562590</td><td>-0.01437793 </td><td> 1.00000000 </td><td>-0.017044085</td><td>-0.2295603  </td><td>-0.2457687  </td><td>-0.3508766  </td></tr>\n",
       "\t<tr><th scope=row>test.preparation.course</th><td> 0.006027952</td><td>-0.017508038</td><td>-0.01155751 </td><td>-0.01704409 </td><td> 1.000000000</td><td>-0.2417804  </td><td>-0.3129463  </td><td>-0.1777025  </td></tr>\n",
       "\t<tr><th scope=row>reading.score</th><td> 0.244312608</td><td> 0.145252622</td><td>-0.14342932 </td><td>-0.22956032 </td><td>-0.241780434</td><td> 1.0000000  </td><td> 0.9545981  </td><td> 0.8175797  </td></tr>\n",
       "\t<tr><th scope=row>writing.score</th><td> 0.301224936</td><td> 0.165690511</td><td>-0.19233808 </td><td>-0.24576868 </td><td>-0.312946284</td><td> 0.9545981  </td><td> 1.0000000  </td><td> 0.8026420  </td></tr>\n",
       "\t<tr><th scope=row>math.score</th><td>-0.167982238</td><td> 0.216415448</td><td>-0.13923560 </td><td>-0.35087665 </td><td>-0.177702469</td><td> 0.8175797  </td><td> 0.8026420  </td><td> 1.0000000  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllll}\n",
       "  & gender & race.ethnicity & parental.level.of.education & lunch & test.preparation.course & reading.score & writing.score & math.score\\\\\n",
       "\\hline\n",
       "\tgender &  1.000000000 &  0.001501924 & -0.02838346  &  0.02137167  &  0.006027952 &  0.2443126   &  0.3012249   & -0.1679822  \\\\\n",
       "\trace.ethnicity &  0.001501924 &  1.000000000 & -0.08048602  & -0.04656259  & -0.017508038 &  0.1452526   &  0.1656905   &  0.2164154  \\\\\n",
       "\tparental.level.of.education & -0.028383460 & -0.080486016 &  1.00000000  & -0.01437793  & -0.011557512 & -0.1434293   & -0.1923381   & -0.1392356  \\\\\n",
       "\tlunch &  0.021371670 & -0.046562590 & -0.01437793  &  1.00000000  & -0.017044085 & -0.2295603   & -0.2457687   & -0.3508766  \\\\\n",
       "\ttest.preparation.course &  0.006027952 & -0.017508038 & -0.01155751  & -0.01704409  &  1.000000000 & -0.2417804   & -0.3129463   & -0.1777025  \\\\\n",
       "\treading.score &  0.244312608 &  0.145252622 & -0.14342932  & -0.22956032  & -0.241780434 &  1.0000000   &  0.9545981   &  0.8175797  \\\\\n",
       "\twriting.score &  0.301224936 &  0.165690511 & -0.19233808  & -0.24576868  & -0.312946284 &  0.9545981   &  1.0000000   &  0.8026420  \\\\\n",
       "\tmath.score & -0.167982238 &  0.216415448 & -0.13923560  & -0.35087665  & -0.177702469 &  0.8175797   &  0.8026420   &  1.0000000  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | gender | race.ethnicity | parental.level.of.education | lunch | test.preparation.course | reading.score | writing.score | math.score | \n",
       "|---|---|---|---|---|---|---|---|\n",
       "| gender |  1.000000000 |  0.001501924 | -0.02838346  |  0.02137167  |  0.006027952 |  0.2443126   |  0.3012249   | -0.1679822   | \n",
       "| race.ethnicity |  0.001501924 |  1.000000000 | -0.08048602  | -0.04656259  | -0.017508038 |  0.1452526   |  0.1656905   |  0.2164154   | \n",
       "| parental.level.of.education | -0.028383460 | -0.080486016 |  1.00000000  | -0.01437793  | -0.011557512 | -0.1434293   | -0.1923381   | -0.1392356   | \n",
       "| lunch |  0.021371670 | -0.046562590 | -0.01437793  |  1.00000000  | -0.017044085 | -0.2295603   | -0.2457687   | -0.3508766   | \n",
       "| test.preparation.course |  0.006027952 | -0.017508038 | -0.01155751  | -0.01704409  |  1.000000000 | -0.2417804   | -0.3129463   | -0.1777025   | \n",
       "| reading.score |  0.244312608 |  0.145252622 | -0.14342932  | -0.22956032  | -0.241780434 |  1.0000000   |  0.9545981   |  0.8175797   | \n",
       "| writing.score |  0.301224936 |  0.165690511 | -0.19233808  | -0.24576868  | -0.312946284 |  0.9545981   |  1.0000000   |  0.8026420   | \n",
       "| math.score | -0.167982238 |  0.216415448 | -0.13923560  | -0.35087665  | -0.177702469 |  0.8175797   |  0.8026420   |  1.0000000   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "                            gender       race.ethnicity\n",
       "gender                       1.000000000  0.001501924  \n",
       "race.ethnicity               0.001501924  1.000000000  \n",
       "parental.level.of.education -0.028383460 -0.080486016  \n",
       "lunch                        0.021371670 -0.046562590  \n",
       "test.preparation.course      0.006027952 -0.017508038  \n",
       "reading.score                0.244312608  0.145252622  \n",
       "writing.score                0.301224936  0.165690511  \n",
       "math.score                  -0.167982238  0.216415448  \n",
       "                            parental.level.of.education lunch      \n",
       "gender                      -0.02838346                  0.02137167\n",
       "race.ethnicity              -0.08048602                 -0.04656259\n",
       "parental.level.of.education  1.00000000                 -0.01437793\n",
       "lunch                       -0.01437793                  1.00000000\n",
       "test.preparation.course     -0.01155751                 -0.01704409\n",
       "reading.score               -0.14342932                 -0.22956032\n",
       "writing.score               -0.19233808                 -0.24576868\n",
       "math.score                  -0.13923560                 -0.35087665\n",
       "                            test.preparation.course reading.score writing.score\n",
       "gender                       0.006027952             0.2443126     0.3012249   \n",
       "race.ethnicity              -0.017508038             0.1452526     0.1656905   \n",
       "parental.level.of.education -0.011557512            -0.1434293    -0.1923381   \n",
       "lunch                       -0.017044085            -0.2295603    -0.2457687   \n",
       "test.preparation.course      1.000000000            -0.2417804    -0.3129463   \n",
       "reading.score               -0.241780434             1.0000000     0.9545981   \n",
       "writing.score               -0.312946284             0.9545981     1.0000000   \n",
       "math.score                  -0.177702469             0.8175797     0.8026420   \n",
       "                            math.score\n",
       "gender                      -0.1679822\n",
       "race.ethnicity               0.2164154\n",
       "parental.level.of.education -0.1392356\n",
       "lunch                       -0.3508766\n",
       "test.preparation.course     -0.1777025\n",
       "reading.score                0.8175797\n",
       "writing.score                0.8026420\n",
       "math.score                   1.0000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We use a Pearson Corrlelation tets to determine if there are any correlations amongst variables...\n",
    "cor(df, method = 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " reading.score    writing.score      math.score    \n",
       " Min.   : 17.00   Min.   : 10.00   Min.   :  0.00  \n",
       " 1st Qu.: 59.00   1st Qu.: 57.75   1st Qu.: 57.00  \n",
       " Median : 70.00   Median : 69.00   Median : 66.00  \n",
       " Mean   : 69.17   Mean   : 68.05   Mean   : 66.09  \n",
       " 3rd Qu.: 79.00   3rd Qu.: 79.00   3rd Qu.: 77.00  \n",
       " Max.   :100.00   Max.   :100.00   Max.   :100.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Well... all features seem to have a low correlation with the desired predicted variables...\n",
    "# The only things worth mentioning are:\n",
    "# The Reading and Writing scores show a very high positive corrleation.\n",
    "# The Math score has an appreciable positive correlation to the Writing score and the Reading score.\n",
    "# We view our scores...\n",
    "summary(df[6:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       " randomForest(x = x_train, y = y_train, importance = TRUE) \n",
       "               Type of random forest: regression\n",
       "                     Number of trees: 500\n",
       "No. of variables tried at each split: 2\n",
       "\n",
       "          Mean of squared residuals: 4.381626\n",
       "                    % Var explained: 97.94"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It looks like a high C is the average score for each of the three tests...\n",
    "# A more in-depth analysis of data must occur, specifically, data visualization.\n",
    "# I assume our data is clustered due to the categorical nature of the features.\n",
    "# Meaning, plotting the data would provide rich insight for clustering.\n",
    "# We move to a Machine Learning model for now.\n",
    "# We split our data for training and testing...\n",
    "sample <- sample.split(df, SplitRatio = .75)\n",
    "train <- subset(df, sample == TRUE)\n",
    "test  <- subset(df, sample == FALSE)\n",
    "\n",
    "# We split our training data into the X and y vectors...\n",
    "x_train = train[c(1,2,3,4,5,6,7)]\n",
    "y_train = train[,6]\n",
    "\n",
    "# We split our testing data into the X and y vectors...\n",
    "x_test = test[c(1,2,3,4,5,6,7)]\n",
    "y_test = test[,6]\n",
    "\n",
    "# We seek to predict the Math Score of the individuals.\n",
    "# We will include the Reading and Writing scores within the model as well...\n",
    "# We create the model...\n",
    "Predict_Math_Score <- randomForest(\n",
    "    x = x_train,\n",
    "    y = y_train,\n",
    "    importance = TRUE,\n",
    ")\n",
    "Predict_Math_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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",
      "text/plain": [
       "Plot with title \"Predict_Math_Score\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# While the % Var Explained will need to be determined for Overfitting, we have a model!\n",
    "plot(Predict_Math_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1.23151520879921"
      ],
      "text/latex": [
       "1.23151520879921"
      ],
      "text/markdown": [
       "1.23151520879921"
      ],
      "text/plain": [
       "[1] 1.231515"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# As the figure displays, as we add more Trees to the model, the lower our error seems to appear.\n",
    "# We now predict our test set and determine the RMSE for the predictions.\n",
    "mean(sqrt((y_test - predict(Predict_Math_Score, x_test))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>%IncMSE</th><th scope=col>IncNodePurity</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>gender</th><td> 8.6884428</td><td> 3230.151 </td></tr>\n",
       "\t<tr><th scope=row>race.ethnicity</th><td>-0.2884227</td><td> 1834.442 </td></tr>\n",
       "\t<tr><th scope=row>parental.level.of.education</th><td> 2.2739181</td><td> 2534.039 </td></tr>\n",
       "\t<tr><th scope=row>lunch</th><td> 8.0446732</td><td> 2789.480 </td></tr>\n",
       "\t<tr><th scope=row>test.preparation.course</th><td> 7.4280766</td><td> 1908.863 </td></tr>\n",
       "\t<tr><th scope=row>reading.score</th><td>44.9236804</td><td>81048.227 </td></tr>\n",
       "\t<tr><th scope=row>writing.score</th><td>31.2192291</td><td>58733.207 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & \\%IncMSE & IncNodePurity\\\\\n",
       "\\hline\n",
       "\tgender &  8.6884428 &  3230.151 \\\\\n",
       "\trace.ethnicity & -0.2884227 &  1834.442 \\\\\n",
       "\tparental.level.of.education &  2.2739181 &  2534.039 \\\\\n",
       "\tlunch &  8.0446732 &  2789.480 \\\\\n",
       "\ttest.preparation.course &  7.4280766 &  1908.863 \\\\\n",
       "\treading.score & 44.9236804 & 81048.227 \\\\\n",
       "\twriting.score & 31.2192291 & 58733.207 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | %IncMSE | IncNodePurity | \n",
       "|---|---|---|---|---|---|---|\n",
       "| gender |  8.6884428 |  3230.151  | \n",
       "| race.ethnicity | -0.2884227 |  1834.442  | \n",
       "| parental.level.of.education |  2.2739181 |  2534.039  | \n",
       "| lunch |  8.0446732 |  2789.480  | \n",
       "| test.preparation.course |  7.4280766 |  1908.863  | \n",
       "| reading.score | 44.9236804 | 81048.227  | \n",
       "| writing.score | 31.2192291 | 58733.207  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "                            %IncMSE    IncNodePurity\n",
       "gender                       8.6884428  3230.151    \n",
       "race.ethnicity              -0.2884227  1834.442    \n",
       "parental.level.of.education  2.2739181  2534.039    \n",
       "lunch                        8.0446732  2789.480    \n",
       "test.preparation.course      7.4280766  1908.863    \n",
       "reading.score               44.9236804 81048.227    \n",
       "writing.score               31.2192291 58733.207    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# On average, it looks like our predicted Math test score deviated by 1.53 points from the actual Math test score.\n",
    "importance(Predict_Math_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       " randomForest(x = x_train, y = y_train, importance = TRUE) \n",
       "               Type of random forest: regression\n",
       "                     Number of trees: 500\n",
       "No. of variables tried at each split: 1\n",
       "\n",
       "          Mean of squared residuals: 185.8035\n",
       "                    % Var explained: 19.63"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It also appears that the reading.score and the writing.score had the highest importance in predicting the\n",
    "# math.score. This aligns with our Correlation test!\n",
    "# Let's drop the columns and teach a new Random Forest algorithm. \n",
    "# This time, we drop the Reading and Writing test scores in case if the Math test is taken before the Reading\n",
    "# and writing tests...\n",
    "# We split our data for training and testing...\n",
    "sample <- sample.split(df, SplitRatio = .75)\n",
    "train <- subset(df[c(1,2,3,4,5,8)], sample == TRUE)\n",
    "test  <- subset(df[c(1,2,3,4,5,8)], sample == FALSE)\n",
    "\n",
    "# We split our training data into the X and y vectors...\n",
    "x_train = train[c(1,2,3,4,5)]\n",
    "y_train = train[,6]\n",
    "\n",
    "# We split our testing data into the X and y vectors...\n",
    "x_test = test[c(1,2,3,4,5)]\n",
    "y_test = test[,6]\n",
    "\n",
    "# We create the model without the Reading and Writing scores...\n",
    "Math_Score_No_Tests.rf <- randomForest(\n",
    "    x = x_train,\n",
    "    y = y_train,\n",
    "    importance = TRUE,\n",
    ")\n",
    "Math_Score_No_Tests.rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nAoQEAf8BYMyv/3N4EBEAAAAASUVORK5CYII=",
      "text/plain": [
       "Plot with title \"Math_Score_No_Tests.rf\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Yikes... the % Var. explained is alarmingly low... especially when compared to the previous model.\n",
    "# let's see how well the tree number influences the error.\n",
    "plot(Math_Score_No_Tests.rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "11.2526742501218"
      ],
      "text/latex": [
       "11.2526742501218"
      ],
      "text/markdown": [
       "11.2526742501218"
      ],
      "text/plain": [
       "[1] 11.25267"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It appears our tree value is optimized to minimize the error...\n",
    "# Let us calculate the actual RMSE for a prediction on the test set.\n",
    "mean(sqrt((y_test - predict(Math_Score_No_Tests.rf, x_test))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>%IncMSE</th><th scope=col>IncNodePurity</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>gender</th><td>16.05360 </td><td> 3838.737</td></tr>\n",
       "\t<tr><th scope=row>race.ethnicity</th><td>16.31127 </td><td> 5923.159</td></tr>\n",
       "\t<tr><th scope=row>parental.level.of.education</th><td>14.49475 </td><td> 5417.350</td></tr>\n",
       "\t<tr><th scope=row>lunch</th><td>33.85978 </td><td>13303.236</td></tr>\n",
       "\t<tr><th scope=row>test.preparation.course</th><td>22.53119 </td><td> 4932.731</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & \\%IncMSE & IncNodePurity\\\\\n",
       "\\hline\n",
       "\tgender & 16.05360  &  3838.737\\\\\n",
       "\trace.ethnicity & 16.31127  &  5923.159\\\\\n",
       "\tparental.level.of.education & 14.49475  &  5417.350\\\\\n",
       "\tlunch & 33.85978  & 13303.236\\\\\n",
       "\ttest.preparation.course & 22.53119  &  4932.731\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | %IncMSE | IncNodePurity | \n",
       "|---|---|---|---|---|\n",
       "| gender | 16.05360  |  3838.737 | \n",
       "| race.ethnicity | 16.31127  |  5923.159 | \n",
       "| parental.level.of.education | 14.49475  |  5417.350 | \n",
       "| lunch | 33.85978  | 13303.236 | \n",
       "| test.preparation.course | 22.53119  |  4932.731 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "                            %IncMSE  IncNodePurity\n",
       "gender                      16.05360  3838.737    \n",
       "race.ethnicity              16.31127  5923.159    \n",
       "parental.level.of.education 14.49475  5417.350    \n",
       "lunch                       33.85978 13303.236    \n",
       "test.preparation.course     22.53119  4932.731    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Surprisingly, the type of lunch had the largest influence on the predictions of our test set...\n",
    "importance(Math_Score_No_Tests.rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It appears dropping the Reading and Writing score significantly affected the results of this model...\n",
    "# Recommendations: Optimize the current model and visualize the data more appropriately.\n",
    "# It may be more worthwhile to compare which variables most influence the Reading Score and the Writing Score as well.\n",
    "# Then, feature importance can be cross-validated between this model and the Reading and Writing score models...\n",
    "# It may be beneficial to use the score values to predict the parent's level of education in the future..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Do:\n",
    "Data Visualization <br>\n",
    "Display Tree Paths <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
