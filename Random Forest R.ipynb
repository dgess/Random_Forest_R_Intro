{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>gender</th><th scope=col>race.ethnicity</th><th scope=col>parental.level.of.education</th><th scope=col>lunch</th><th scope=col>test.preparation.course</th><th scope=col>reading.score</th><th scope=col>writing.score</th><th scope=col>math.score</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>female            </td><td>group B           </td><td>bachelor's degree </td><td>standard          </td><td>none              </td><td>72                </td><td>74                </td><td>72                </td></tr>\n",
       "\t<tr><td>female            </td><td>group C           </td><td>some college      </td><td>standard          </td><td>completed         </td><td>90                </td><td>88                </td><td>69                </td></tr>\n",
       "\t<tr><td>female            </td><td>group B           </td><td>master's degree   </td><td>standard          </td><td>none              </td><td>95                </td><td>93                </td><td>90                </td></tr>\n",
       "\t<tr><td>male              </td><td>group A           </td><td>associate's degree</td><td>free/reduced      </td><td>none              </td><td>57                </td><td>44                </td><td>47                </td></tr>\n",
       "\t<tr><td>male              </td><td>group C           </td><td>some college      </td><td>standard          </td><td>none              </td><td>78                </td><td>75                </td><td>76                </td></tr>\n",
       "\t<tr><td>female            </td><td>group B           </td><td>associate's degree</td><td>standard          </td><td>none              </td><td>83                </td><td>78                </td><td>71                </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllll}\n",
       " gender & race.ethnicity & parental.level.of.education & lunch & test.preparation.course & reading.score & writing.score & math.score\\\\\n",
       "\\hline\n",
       "\t female             & group B            & bachelor's degree  & standard           & none               & 72                 & 74                 & 72                \\\\\n",
       "\t female             & group C            & some college       & standard           & completed          & 90                 & 88                 & 69                \\\\\n",
       "\t female             & group B            & master's degree    & standard           & none               & 95                 & 93                 & 90                \\\\\n",
       "\t male               & group A            & associate's degree & free/reduced       & none               & 57                 & 44                 & 47                \\\\\n",
       "\t male               & group C            & some college       & standard           & none               & 78                 & 75                 & 76                \\\\\n",
       "\t female             & group B            & associate's degree & standard           & none               & 83                 & 78                 & 71                \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "gender | race.ethnicity | parental.level.of.education | lunch | test.preparation.course | reading.score | writing.score | math.score | \n",
       "|---|---|---|---|---|---|\n",
       "| female             | group B            | bachelor's degree  | standard           | none               | 72                 | 74                 | 72                 | \n",
       "| female             | group C            | some college       | standard           | completed          | 90                 | 88                 | 69                 | \n",
       "| female             | group B            | master's degree    | standard           | none               | 95                 | 93                 | 90                 | \n",
       "| male               | group A            | associate's degree | free/reduced       | none               | 57                 | 44                 | 47                 | \n",
       "| male               | group C            | some college       | standard           | none               | 78                 | 75                 | 76                 | \n",
       "| female             | group B            | associate's degree | standard           | none               | 83                 | 78                 | 71                 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  gender race.ethnicity parental.level.of.education lunch       \n",
       "1 female group B        bachelor's degree           standard    \n",
       "2 female group C        some college                standard    \n",
       "3 female group B        master's degree             standard    \n",
       "4 male   group A        associate's degree          free/reduced\n",
       "5 male   group C        some college                standard    \n",
       "6 female group B        associate's degree          standard    \n",
       "  test.preparation.course reading.score writing.score math.score\n",
       "1 none                    72            74            72        \n",
       "2 completed               90            88            69        \n",
       "3 none                    95            93            90        \n",
       "4 none                    57            44            47        \n",
       "5 none                    78            75            76        \n",
       "6 none                    83            78            71        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Visualization\n",
    "library(ggplot2)\n",
    "\n",
    "# Random Forest\n",
    "library(randomForest)\n",
    "require(caTools)\n",
    "\n",
    "# We change our working directory...\n",
    "setwd('C:\\\\Users\\\\...\\\\Downloads\\\\students-performance-in-exams')\n",
    "\n",
    "# We pass our data into an array...\n",
    "df <- read.csv('StudentsPerformance.csv')\n",
    "df <- df[c(1,2,3,4,5,7,8,6)]\n",
    "data <- df\n",
    "\n",
    "# Let's see what we have here...\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] female male  \n",
      "Levels: female male\n",
      "[1] group B group C group A group D group E\n",
      "Levels: group A group B group C group D group E\n",
      "[1] bachelor's degree  some college       master's degree    associate's degree\n",
      "[5] high school        some high school  \n",
      "6 Levels: associate's degree bachelor's degree high school ... some high school\n",
      "[1] standard     free/reduced\n",
      "Levels: free/reduced standard\n",
      "[1] none      completed\n",
      "Levels: completed none\n"
     ]
    }
   ],
   "source": [
    "# It looks like our data does not have too mnay features...\n",
    "# Also, the features all look categorical, but, currently in string form...\n",
    "# We will use integers to clean our features for the algorthim.\n",
    "# We get the unique values in each column for integer-based categories.\n",
    "for (column in 1:5) {\n",
    "    print(unique(df[,column]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We clean the gender column...\n",
    "clean_gender <- function(x) {\n",
    "    if ( x == 'male') {\n",
    "        x = 0\n",
    "    }\n",
    "    \n",
    "    else {\n",
    "        x = 1\n",
    "    }\n",
    "        \n",
    "}\n",
    "df[,1] = sapply(df[,1], clean_gender)\n",
    "\n",
    "# We clean the race.ethnicity column...\n",
    "clean_ethnicity <- function(x) {\n",
    "    if ( x == 'group A') {\n",
    "        x = 0\n",
    "    } else if ( x == 'group B') {\n",
    "        x = 1\n",
    "    } else if ( x == 'group C') {\n",
    "        x = 2\n",
    "    } else if ( x == 'group D') {\n",
    "        x = 3\n",
    "    } else {\n",
    "        x = 4\n",
    "    }\n",
    "}\n",
    "\n",
    "df[,2] = sapply(df[,2], clean_ethnicity)\n",
    "\n",
    "# We clean the parent.level.of.education column...\n",
    "clean_education <- function(x) {\n",
    "    if ( x == \"bachelor's degree\") {\n",
    "        x = 0 \n",
    "    } else if ( x == \"some college\") {\n",
    "        x = 1\n",
    "    } else if ( x == \"master's degree\") {\n",
    "        x = 2\n",
    "    } else if ( x == \"associate's degree\") {\n",
    "        x = 3\n",
    "    } else if ( x == \"high school\") {\n",
    "        x = 4\n",
    "    } else {\n",
    "        x = 5\n",
    "    }\n",
    "}\n",
    "\n",
    "df[,3] = sapply(df[,3], clean_education)\n",
    "\n",
    "# We clean the lunch column...\n",
    "clean_lunch <- function(x) {\n",
    "    if ( x == 'standard') {\n",
    "        x = 0\n",
    "    } else {\n",
    "        x = 1\n",
    "    }\n",
    "}\n",
    "\n",
    "df[,4] = sapply(df[,4], clean_lunch)\n",
    "\n",
    "# We clean the test.preparation.course column...\n",
    "clean_prep <- function(x) {\n",
    "    if ( x == 'completed') {\n",
    "        x = 0\n",
    "    } else {\n",
    "        x = 1\n",
    "    }\n",
    "}\n",
    "\n",
    "df[,5] = sapply(df[,5], clean_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>gender</th><th scope=col>race.ethnicity</th><th scope=col>parental.level.of.education</th><th scope=col>lunch</th><th scope=col>test.preparation.course</th><th scope=col>reading.score</th><th scope=col>writing.score</th><th scope=col>math.score</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1 </td><td>1 </td><td>0 </td><td>0 </td><td>1 </td><td>72</td><td>74</td><td>72</td></tr>\n",
       "\t<tr><td>1 </td><td>2 </td><td>1 </td><td>0 </td><td>0 </td><td>90</td><td>88</td><td>69</td></tr>\n",
       "\t<tr><td>1 </td><td>1 </td><td>2 </td><td>0 </td><td>1 </td><td>95</td><td>93</td><td>90</td></tr>\n",
       "\t<tr><td>0 </td><td>0 </td><td>3 </td><td>1 </td><td>1 </td><td>57</td><td>44</td><td>47</td></tr>\n",
       "\t<tr><td>0 </td><td>2 </td><td>1 </td><td>0 </td><td>1 </td><td>78</td><td>75</td><td>76</td></tr>\n",
       "\t<tr><td>1 </td><td>1 </td><td>3 </td><td>0 </td><td>1 </td><td>83</td><td>78</td><td>71</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllll}\n",
       " gender & race.ethnicity & parental.level.of.education & lunch & test.preparation.course & reading.score & writing.score & math.score\\\\\n",
       "\\hline\n",
       "\t 1  & 1  & 0  & 0  & 1  & 72 & 74 & 72\\\\\n",
       "\t 1  & 2  & 1  & 0  & 0  & 90 & 88 & 69\\\\\n",
       "\t 1  & 1  & 2  & 0  & 1  & 95 & 93 & 90\\\\\n",
       "\t 0  & 0  & 3  & 1  & 1  & 57 & 44 & 47\\\\\n",
       "\t 0  & 2  & 1  & 0  & 1  & 78 & 75 & 76\\\\\n",
       "\t 1  & 1  & 3  & 0  & 1  & 83 & 78 & 71\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "gender | race.ethnicity | parental.level.of.education | lunch | test.preparation.course | reading.score | writing.score | math.score | \n",
       "|---|---|---|---|---|---|\n",
       "| 1  | 1  | 0  | 0  | 1  | 72 | 74 | 72 | \n",
       "| 1  | 2  | 1  | 0  | 0  | 90 | 88 | 69 | \n",
       "| 1  | 1  | 2  | 0  | 1  | 95 | 93 | 90 | \n",
       "| 0  | 0  | 3  | 1  | 1  | 57 | 44 | 47 | \n",
       "| 0  | 2  | 1  | 0  | 1  | 78 | 75 | 76 | \n",
       "| 1  | 1  | 3  | 0  | 1  | 83 | 78 | 71 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  gender race.ethnicity parental.level.of.education lunch\n",
       "1 1      1              0                           0    \n",
       "2 1      2              1                           0    \n",
       "3 1      1              2                           0    \n",
       "4 0      0              3                           1    \n",
       "5 0      2              1                           0    \n",
       "6 1      1              3                           0    \n",
       "  test.preparation.course reading.score writing.score math.score\n",
       "1 1                       72            74            72        \n",
       "2 0                       90            88            69        \n",
       "3 1                       95            93            90        \n",
       "4 1                       57            44            47        \n",
       "5 1                       78            75            76        \n",
       "6 1                       83            78            71        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We spot-check that the integer-based categories have successfully updated...\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>gender</th><th scope=col>race.ethnicity</th><th scope=col>parental.level.of.education</th><th scope=col>lunch</th><th scope=col>test.preparation.course</th><th scope=col>reading.score</th><th scope=col>writing.score</th><th scope=col>math.score</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>gender</th><td> 1.000000000</td><td> 0.001501924</td><td>-0.02838346 </td><td> 0.02137167 </td><td> 0.006027952</td><td> 0.2443126  </td><td> 0.3012249  </td><td>-0.1679822  </td></tr>\n",
       "\t<tr><th scope=row>race.ethnicity</th><td> 0.001501924</td><td> 1.000000000</td><td>-0.08048602 </td><td>-0.04656259 </td><td>-0.017508038</td><td> 0.1452526  </td><td> 0.1656905  </td><td> 0.2164154  </td></tr>\n",
       "\t<tr><th scope=row>parental.level.of.education</th><td>-0.028383460</td><td>-0.080486016</td><td> 1.00000000 </td><td>-0.01437793 </td><td>-0.011557512</td><td>-0.1434293  </td><td>-0.1923381  </td><td>-0.1392356  </td></tr>\n",
       "\t<tr><th scope=row>lunch</th><td> 0.021371670</td><td>-0.046562590</td><td>-0.01437793 </td><td> 1.00000000 </td><td>-0.017044085</td><td>-0.2295603  </td><td>-0.2457687  </td><td>-0.3508766  </td></tr>\n",
       "\t<tr><th scope=row>test.preparation.course</th><td> 0.006027952</td><td>-0.017508038</td><td>-0.01155751 </td><td>-0.01704409 </td><td> 1.000000000</td><td>-0.2417804  </td><td>-0.3129463  </td><td>-0.1777025  </td></tr>\n",
       "\t<tr><th scope=row>reading.score</th><td> 0.244312608</td><td> 0.145252622</td><td>-0.14342932 </td><td>-0.22956032 </td><td>-0.241780434</td><td> 1.0000000  </td><td> 0.9545981  </td><td> 0.8175797  </td></tr>\n",
       "\t<tr><th scope=row>writing.score</th><td> 0.301224936</td><td> 0.165690511</td><td>-0.19233808 </td><td>-0.24576868 </td><td>-0.312946284</td><td> 0.9545981  </td><td> 1.0000000  </td><td> 0.8026420  </td></tr>\n",
       "\t<tr><th scope=row>math.score</th><td>-0.167982238</td><td> 0.216415448</td><td>-0.13923560 </td><td>-0.35087665 </td><td>-0.177702469</td><td> 0.8175797  </td><td> 0.8026420  </td><td> 1.0000000  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllll}\n",
       "  & gender & race.ethnicity & parental.level.of.education & lunch & test.preparation.course & reading.score & writing.score & math.score\\\\\n",
       "\\hline\n",
       "\tgender &  1.000000000 &  0.001501924 & -0.02838346  &  0.02137167  &  0.006027952 &  0.2443126   &  0.3012249   & -0.1679822  \\\\\n",
       "\trace.ethnicity &  0.001501924 &  1.000000000 & -0.08048602  & -0.04656259  & -0.017508038 &  0.1452526   &  0.1656905   &  0.2164154  \\\\\n",
       "\tparental.level.of.education & -0.028383460 & -0.080486016 &  1.00000000  & -0.01437793  & -0.011557512 & -0.1434293   & -0.1923381   & -0.1392356  \\\\\n",
       "\tlunch &  0.021371670 & -0.046562590 & -0.01437793  &  1.00000000  & -0.017044085 & -0.2295603   & -0.2457687   & -0.3508766  \\\\\n",
       "\ttest.preparation.course &  0.006027952 & -0.017508038 & -0.01155751  & -0.01704409  &  1.000000000 & -0.2417804   & -0.3129463   & -0.1777025  \\\\\n",
       "\treading.score &  0.244312608 &  0.145252622 & -0.14342932  & -0.22956032  & -0.241780434 &  1.0000000   &  0.9545981   &  0.8175797  \\\\\n",
       "\twriting.score &  0.301224936 &  0.165690511 & -0.19233808  & -0.24576868  & -0.312946284 &  0.9545981   &  1.0000000   &  0.8026420  \\\\\n",
       "\tmath.score & -0.167982238 &  0.216415448 & -0.13923560  & -0.35087665  & -0.177702469 &  0.8175797   &  0.8026420   &  1.0000000  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | gender | race.ethnicity | parental.level.of.education | lunch | test.preparation.course | reading.score | writing.score | math.score | \n",
       "|---|---|---|---|---|---|---|---|\n",
       "| gender |  1.000000000 |  0.001501924 | -0.02838346  |  0.02137167  |  0.006027952 |  0.2443126   |  0.3012249   | -0.1679822   | \n",
       "| race.ethnicity |  0.001501924 |  1.000000000 | -0.08048602  | -0.04656259  | -0.017508038 |  0.1452526   |  0.1656905   |  0.2164154   | \n",
       "| parental.level.of.education | -0.028383460 | -0.080486016 |  1.00000000  | -0.01437793  | -0.011557512 | -0.1434293   | -0.1923381   | -0.1392356   | \n",
       "| lunch |  0.021371670 | -0.046562590 | -0.01437793  |  1.00000000  | -0.017044085 | -0.2295603   | -0.2457687   | -0.3508766   | \n",
       "| test.preparation.course |  0.006027952 | -0.017508038 | -0.01155751  | -0.01704409  |  1.000000000 | -0.2417804   | -0.3129463   | -0.1777025   | \n",
       "| reading.score |  0.244312608 |  0.145252622 | -0.14342932  | -0.22956032  | -0.241780434 |  1.0000000   |  0.9545981   |  0.8175797   | \n",
       "| writing.score |  0.301224936 |  0.165690511 | -0.19233808  | -0.24576868  | -0.312946284 |  0.9545981   |  1.0000000   |  0.8026420   | \n",
       "| math.score | -0.167982238 |  0.216415448 | -0.13923560  | -0.35087665  | -0.177702469 |  0.8175797   |  0.8026420   |  1.0000000   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "                            gender       race.ethnicity\n",
       "gender                       1.000000000  0.001501924  \n",
       "race.ethnicity               0.001501924  1.000000000  \n",
       "parental.level.of.education -0.028383460 -0.080486016  \n",
       "lunch                        0.021371670 -0.046562590  \n",
       "test.preparation.course      0.006027952 -0.017508038  \n",
       "reading.score                0.244312608  0.145252622  \n",
       "writing.score                0.301224936  0.165690511  \n",
       "math.score                  -0.167982238  0.216415448  \n",
       "                            parental.level.of.education lunch      \n",
       "gender                      -0.02838346                  0.02137167\n",
       "race.ethnicity              -0.08048602                 -0.04656259\n",
       "parental.level.of.education  1.00000000                 -0.01437793\n",
       "lunch                       -0.01437793                  1.00000000\n",
       "test.preparation.course     -0.01155751                 -0.01704409\n",
       "reading.score               -0.14342932                 -0.22956032\n",
       "writing.score               -0.19233808                 -0.24576868\n",
       "math.score                  -0.13923560                 -0.35087665\n",
       "                            test.preparation.course reading.score writing.score\n",
       "gender                       0.006027952             0.2443126     0.3012249   \n",
       "race.ethnicity              -0.017508038             0.1452526     0.1656905   \n",
       "parental.level.of.education -0.011557512            -0.1434293    -0.1923381   \n",
       "lunch                       -0.017044085            -0.2295603    -0.2457687   \n",
       "test.preparation.course      1.000000000            -0.2417804    -0.3129463   \n",
       "reading.score               -0.241780434             1.0000000     0.9545981   \n",
       "writing.score               -0.312946284             0.9545981     1.0000000   \n",
       "math.score                  -0.177702469             0.8175797     0.8026420   \n",
       "                            math.score\n",
       "gender                      -0.1679822\n",
       "race.ethnicity               0.2164154\n",
       "parental.level.of.education -0.1392356\n",
       "lunch                       -0.3508766\n",
       "test.preparation.course     -0.1777025\n",
       "reading.score                0.8175797\n",
       "writing.score                0.8026420\n",
       "math.score                   1.0000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We use a Pearson Corrlelation tets to determine if there are any correlations amongst variables...\n",
    "cor(df, method = 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " reading.score    writing.score      math.score    \n",
       " Min.   : 17.00   Min.   : 10.00   Min.   :  0.00  \n",
       " 1st Qu.: 59.00   1st Qu.: 57.75   1st Qu.: 57.00  \n",
       " Median : 70.00   Median : 69.00   Median : 66.00  \n",
       " Mean   : 69.17   Mean   : 68.05   Mean   : 66.09  \n",
       " 3rd Qu.: 79.00   3rd Qu.: 79.00   3rd Qu.: 77.00  \n",
       " Max.   :100.00   Max.   :100.00   Max.   :100.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Well... all features seem to have a low correlation with the desired predicted variables...\n",
    "# The only things worth mentioning are:\n",
    "# The Reading and Writing scores show a very high positive corrleation.\n",
    "# The Math score has an appreciable positive correlation to the Writing score and the Reading score.\n",
    "# We view our scores...\n",
    "summary(df[6:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       " randomForest(x = x_train, y = y_train, importance = TRUE) \n",
       "               Type of random forest: regression\n",
       "                     Number of trees: 500\n",
       "No. of variables tried at each split: 2\n",
       "\n",
       "          Mean of squared residuals: 4.381626\n",
       "                    % Var explained: 97.94"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It looks like a high C is the average score for each of the three tests...\n",
    "# A more in-depth analysis of data must occur, specifically, data visualization.\n",
    "# I assume our data is clustered due to the categorical nature of the features.\n",
    "# Meaning, plotting the data would provide rich insight for clustering.\n",
    "# We move to a Machine Learning model for now.\n",
    "# We split our data for training and testing...\n",
    "sample <- sample.split(df, SplitRatio = .75)\n",
    "train <- subset(df, sample == TRUE)\n",
    "test  <- subset(df, sample == FALSE)\n",
    "\n",
    "# We split our training data into the X and y vectors...\n",
    "x_train = train[c(1,2,3,4,5,6,7)]\n",
    "y_train = train[,6]\n",
    "\n",
    "# We split our testing data into the X and y vectors...\n",
    "x_test = test[c(1,2,3,4,5,6,7)]\n",
    "y_test = test[,6]\n",
    "\n",
    "# We seek to predict the Math Score of the individuals.\n",
    "# We will include the Reading and Writing scores within the model as well...\n",
    "# We create the model...\n",
    "Predict_Math_Score <- randomForest(\n",
    "    x = x_train,\n",
    "    y = y_train,\n",
    "    importance = TRUE,\n",
    ")\n",
    "Predict_Math_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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",
      "text/plain": [
       "Plot with title \"Predict_Math_Score\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# While the % Var Explained will need to be determined for Overfitting, we have a model!\n",
    "plot(Predict_Math_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1.23151520879921"
      ],
      "text/latex": [
       "1.23151520879921"
      ],
      "text/markdown": [
       "1.23151520879921"
      ],
      "text/plain": [
       "[1] 1.231515"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# As the figure displays, as we add more Trees to the model, the lower our error seems to appear.\n",
    "# We now predict our test set and determine the RMSE for the predictions.\n",
    "mean(sqrt((y_test - predict(Predict_Math_Score, x_test))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>%IncMSE</th><th scope=col>IncNodePurity</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>gender</th><td> 8.6884428</td><td> 3230.151 </td></tr>\n",
       "\t<tr><th scope=row>race.ethnicity</th><td>-0.2884227</td><td> 1834.442 </td></tr>\n",
       "\t<tr><th scope=row>parental.level.of.education</th><td> 2.2739181</td><td> 2534.039 </td></tr>\n",
       "\t<tr><th scope=row>lunch</th><td> 8.0446732</td><td> 2789.480 </td></tr>\n",
       "\t<tr><th scope=row>test.preparation.course</th><td> 7.4280766</td><td> 1908.863 </td></tr>\n",
       "\t<tr><th scope=row>reading.score</th><td>44.9236804</td><td>81048.227 </td></tr>\n",
       "\t<tr><th scope=row>writing.score</th><td>31.2192291</td><td>58733.207 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & \\%IncMSE & IncNodePurity\\\\\n",
       "\\hline\n",
       "\tgender &  8.6884428 &  3230.151 \\\\\n",
       "\trace.ethnicity & -0.2884227 &  1834.442 \\\\\n",
       "\tparental.level.of.education &  2.2739181 &  2534.039 \\\\\n",
       "\tlunch &  8.0446732 &  2789.480 \\\\\n",
       "\ttest.preparation.course &  7.4280766 &  1908.863 \\\\\n",
       "\treading.score & 44.9236804 & 81048.227 \\\\\n",
       "\twriting.score & 31.2192291 & 58733.207 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | %IncMSE | IncNodePurity | \n",
       "|---|---|---|---|---|---|---|\n",
       "| gender |  8.6884428 |  3230.151  | \n",
       "| race.ethnicity | -0.2884227 |  1834.442  | \n",
       "| parental.level.of.education |  2.2739181 |  2534.039  | \n",
       "| lunch |  8.0446732 |  2789.480  | \n",
       "| test.preparation.course |  7.4280766 |  1908.863  | \n",
       "| reading.score | 44.9236804 | 81048.227  | \n",
       "| writing.score | 31.2192291 | 58733.207  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "                            %IncMSE    IncNodePurity\n",
       "gender                       8.6884428  3230.151    \n",
       "race.ethnicity              -0.2884227  1834.442    \n",
       "parental.level.of.education  2.2739181  2534.039    \n",
       "lunch                        8.0446732  2789.480    \n",
       "test.preparation.course      7.4280766  1908.863    \n",
       "reading.score               44.9236804 81048.227    \n",
       "writing.score               31.2192291 58733.207    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# On average, it looks like our predicted Math test score deviated by 1.53 points from the actual Math test score.\n",
    "importance(Predict_Math_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       " randomForest(x = x_train, y = y_train, importance = TRUE) \n",
       "               Type of random forest: regression\n",
       "                     Number of trees: 500\n",
       "No. of variables tried at each split: 1\n",
       "\n",
       "          Mean of squared residuals: 193.054\n",
       "                    % Var explained: 18.81"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It also appears that the reading.score and the writing.score had the highest importance in predicting the\n",
    "# math.score. This aligns with our Correlation test!\n",
    "# Let's drop the columns and teach a new Random Forest algorithm. \n",
    "# This time, we drop the Reading and Writing test scores in case if the Math test is taken before the Reading\n",
    "# and writing tests...\n",
    "# We split our data for training and testing...\n",
    "sample <- sample.split(df, SplitRatio = .75)\n",
    "train <- subset(df[c(1,2,3,4,5,8)], sample == TRUE)\n",
    "test  <- subset(df[c(1,2,3,4,5,8)], sample == FALSE)\n",
    "\n",
    "# We split our training data into the X and y vectors...\n",
    "x_train = train[c(1,2,3,4,5)]\n",
    "y_train = train[,6]\n",
    "\n",
    "# We split our testing data into the X and y vectors...\n",
    "x_test = test[c(1,2,3,4,5)]\n",
    "y_test = test[,6]\n",
    "\n",
    "# We create the model without the Reading and Writing scores...\n",
    "Math_Score_No_Tests.rf <- randomForest(\n",
    "    x = x_train,\n",
    "    y = y_train,\n",
    "    importance = TRUE,\n",
    ")\n",
    "Math_Score_No_Tests.rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM\njIyampqnp6eysrK9vb3Hx8fQ0NDZ2dnh4eHp6enw8PD////QFLu4AAAACXBIWXMAABJ0AAAS\ndAHeZh94AAAYcElEQVR4nO3diVri2qKF0RU6EWne/20LQhcQLcFpGhjjfveYwpAVMb9piO6y\nAX6tdL0C8AyEBAFCggAhQYCQIEBIECAkCBASBAgJAoQEAUKCACFBgJAgQEgQICQIEBIECAkC\nhAQBQoIAIUGAkCBASBAgJAgQEgQICQKEBAFCggAhQYCQIEBIECAkCBASBAgJAoQEAUKCACFB\ngJAgQEgQICQIEBIECAkChHSvsrOqJ1f19I15psc5v1nOYlqVMpotUyv1fpr6/7xn/5l3+oOx\n37Zfx0/me25Cule9/e232vfb2+JHVY5zfr2Y2XFTfgutVHWa+v+8Pwzp+IV86223GCEJ6V71\n9jeuJ8e3t8XjY99tp/PztvwRWqnZfwc9z/uzkP6/rK1RKZm96rAJ6V6NDfCLbfEnIW03v9l6\ne3C4bXGSWqnV/wa9sY4tzfT8vAj32m44k1IW26lFPbV/Bd93U6PZ6vQDfz/n5mNbynR1cyn1\nx/VpYrZta7w4fHox3R0vLU7zrkb1Dmc9q0o1u724Q5Gn7fpiEV+Ov7la6vptt5udvG+aX0jj\nweYC9islpJoX4V7bDWe+PymY1lP1Kzg+H6ddhLQ/E6o+b/rbaibNY7pVtX/a/vjsuLjJccRR\nfTR5nOnzweB+lo/Nebu+XMStJ1wP/dGY3o12+kKaD16NOD7N9Oq8BPfahTSpT+2rMjmEtP0w\nXtcXECaXIR18Phevz5Gq6fsxseO2Wu/qJqcnHncypb6+cZypurVSy+2WvTkVcrWIW084TjaX\nOq3HWW/7mJ+/kOaDzQXsVkpIB16Ce+222fnu5/fHdsNa7jei0cUJSjmfI1UfdV6ft/zTlj6q\nD762C6yW9bY6qg8Zy3y9PaA6dFX2mR5yXU9Pl7ovVmq3xPlx8OtF3PoqDlMXSy37L2R9EeXl\ng+cF1Cvl0G7Pi3CvXUir3VXr7Ua6Wl5uRp9C2m3E69ub2mJ0SGl3NHc461qP3lb7Q8Z6ltl+\nX3aMYTvTYdP9tJfZDbGug90Pdr2IW1/FYepiqbu90/m86jDT5YPnzy2ulvTSvAj32oW03bZG\n291QtTmHtHqfjcunkC4+Xlu9T+vDqvnVLOWwaddv+Db+fT5U/LSHq2d820V5+ZTjIm59Feep\n81Lf9lPTi0YuH7xeSSHVvAj3qkPa/sRf7H7WH0N6P+5e7glpZzWpD5iuQ7qYaiynMcr1Sm3q\nXcfq8ilfDn4rpN0jx/eJ6+sjx5kuHrxegJBqXoR71SG919es3o8h7c65R9PjGdMPQqqOP88P\nn/1yj1Q1nl99vcmeVmPyeY904wStOeDVUtfv+ytx4+ZMzQevFyCkmhfhXnVI+7vsVpvzxYbF\n4XObH4U0PZ267Hch4+Y50uTzOVL9z8kXFw7Os5xutbhexFdPuL3U+i2o6xU/Pni9ACHVvAj3\nqgPapbM7JLs8kmrskdabb0PaXVWr36dd7O/4/N9Vu/pJ7/urgO+Xb+g0h1geQ7rjqt3FUken\n07HjrnB9/eD1AoRU8yLc63wuMTv9a1z/YxfF4VSl8bnbm9r5fZ79teXT+0jzTePt3f3e5PT8\n00yf3pE9zjItF/um0yK++Co+LXUb4Hh1uGxx+kIuHvz0RQmp5kW41/lH/nlv8XHYFKt6a5xe\nnWLc3NROW3pV7zE+bt7ZcPXrGIvSnOnzSu0vtZcbi/jyCddLPV5XqPd5xy+k+aCQbvMi3Gu/\n4ey22Mbh23K6u09h9/7S7i2eyeW5ze1Nrf59pDJ5O1x02N3wViaL5icb99ptjjONGjN9WqnN\n/o6JG4v4+gnXS61PhcaHWxgOX0jzQSHd5kWAACFBgJDaUS60u7jw2NzidW2HkJ6c17UdQnpy\nXlcIEBIECAkChAQBQoIAIUGAkCBASBAgJAgQEgQICQKEBAFCggAhQYCQIEBIECAkCBASBAgJ\nAoQEAUKCACFBgJAgQEgQICQIEBIECAkChAQBQoIAIUGAkCBASBAgJAgQEgS0EFKBgXlgK8+H\n08EQkCQkCBASBAgJAoQEAUKCACFBgJAgQEgQICQIEBIECAkChAQBQoIAIUGAkCBASBAgJAgQ\nEgQICQKEBAFCgoABhqQy+kdIECAkCBASBAgJAoQEAUKCACFBgJAgQEgQICQIEBIECAkChAQB\nQoKAIYakJHpHSBAgJAgQEgQICQKEBAFCggAhQYCQIEBIECAkCBASBAgJAoQEAUKCACFBgJAg\nQEgQICQIEBIECAkChAQBQoIAIUGAkCBASBAgJAgQEgQMMSR/Rp/eERIECAkChAQBQoIAIUGA\nkCBASBAgJAgQEgQICQKEBAFCggAhQYCQIEBIECAkCBASBAgJAoQEAUKCACFBgJAgQEgQICQI\nEBIECAkChAQBQoIAIUGAkCBASBAgJAgQEgQICQIGGZKS6BshQcDwQirtrALcQ0gQICQIEBIE\nCAkChAQBQoIAIUGAkCBASBAgJAgQEgQICQKEBAFCggAhQYCQIEBIECAkCBASBAgJAoQEAUKC\nACFBgJAgQEgQICQIEBIECAkChAQBQoIAIUGAkCCg1ZA+3iZlZzL7eHwIIdFDLYa0HpWz8cND\nCIkeajGkWanel/XUalGV2aNDCIkeajGkqixP08tSPTqEkOihFkMq5at/3DWEkOihYe6RlETP\ntHuOtFjVU78+RxISPdPm5e9x46rdaP3oEEKih9p9H2lWv49UTd5++T6SkOiZYd7ZICR6RkgQ\nICQIEBIECAkCWr2z4cKjQwiJHmoxpPn3If20MiHRQ20e2i2r73954mdDCIkeavUcafn9jUE/\nG0JI9FC7FxvmjftWHx1CSPSQq3YQICQIEBIEtBnSelrKeHFYiPeReCZt/hWhav+3uPYLERLP\npNXfkJ1va5rv30wSEk+l1b/ZUH9YVaOVkHgyHfwVofV4LCSeTIshjcrx7zSMxkLiubR60+r0\nMLUqYyHxVNq8/D071bPwaxQ8l3ZvWp0cp1ZTIfFM3NkAAUKCACFBgJAgQEgQICQIEBIECAkC\nhAQBQoIAIUGAkCBASBAgJAgQEgQICQKEBAFCggAhQYCQIEBIECAkCBASBAgJAoQEAUKCACFB\nwEBDUhL9IiQIEBIECAkChAQBQoIAIUGAkCBASBAwuJBKaysBPyckCBASBAgJAoQEAUKCACFB\ngJAgQEgQICQIEBIECAkChAQBQoIAIUGAkCBASBAgJAgQEgQICQKEBAFCggAhQYCQIEBIECAk\nCBASBAgJAoQEAUKCACFBgJAgYKghKYleERIECAkChAQBQoIAIUGAkCBASBAgJAgQEgQICQKE\nBAFCgoDBhqQk+kRIECAkCBASBAgJAoQEAUKCACFBgJAgQEgQICQIEBIECAkChAQBQoIAIUGA\nkCBASBAgJAgQEgQICQKEBAFCggAhQYCQIGC4ISmJHhESBAgJAoQEAUKCACFBgJAgQEgQICQI\nEBIECAkChAQBQoIAIUHAL0OazGJr8tUQX35KSPTHL0Mqf7M1C4mB+WVIo7KOrcoXQ3z5KSHR\nH78MaT0Zf8TW5fYQX35KSPTHrw/tTmKrtBESgyMkCHD5GwKEBAG/Dul9vD2sm7z/6Jkfb5P6\nKHAy+88VCiExML8NaXw4Qxr//3nrUeOM6vv5hcTA/DKkeakW2w+Lqsz/+7xZqd6X9dRqO/+3\nt0QIiYH59Ruy+zSWZfTf51WHeffzVw+u1eeQBEX3UrcI/eDyd7n5xHvX6lNIf3SXEtwjtkf6\ndg9T+4s9UhESvdDuOdJiVU/lzpFK/X/QtRav2p3m3Rl9e7OrkBiY37+PNLnjfaRZ/T5SNXlL\nvI9UH9cJiV4Y8J0NxxMkIdG9Af+GrJDoj1Z/QzZ7i9Dpkp2S6FyLvyGbvkVoc9wbCYnOtfgb\nsulbhE7XGYRE51r8xb70G7JCoj9aDOk/twiV8qOFCYk+avHytz0Sz6vFy9/pW4SERH+0efk7\nfIuQkOiPFi9//8EtQkKiJ1q8/P3gEF9/Skj0RotX7R4c4pvPFCHRE22GtJ6WMl4cn/jYWt36\njJDoXIuXv9fV/ka7/UKExDNpMaTZ7rdo1/Oqvs1OSDyVX4R0xx8zqVX7WVbVaCUknsyvQzqe\n8P/8FqH1eJwNSUl0rsWQzu85jcZC4rm0GNK8TA9TqzIWEk+lxZA2s9NMi/9cLhcSA9NmSJvl\n5Di1mgqJZ9JqSHcP8cPPCImuCQkCfhXSD3+pNblWQqKXhAQBLd4iFBlCSPSSkCDgKUJSEl0T\nEgQICQKEBAHPEZKS6JiQIEBIECAkCBASBAgJAp4pJDXRGSFBgJAg4ElC2j2e/ZUouIeQIEBI\nECAkCHimkFxtoDNCgoDnCcnBHR0SEgQ8V0gO7ujIs4RU742ERFeeJ6T/PRP+kJAg4GlC+uHn\n4U8ICQKEBAFCgoBnC0lJdEJIECAkCHjCkKRE+54xJCXRuucLqTi8o31CgoCnC2kjJDrwfCH9\ndCYIesqQ7JVo2/OGpCRa9MwhSYnWPGtI9km06plDskuiNU8ckgsOtOepQ1ISbXnOkI7nR0Ki\nJUKCgGcN6a654beEBAHPHZKSaMmThvTg7PAgIUGAkCBASBDw5CEpiXY8fUjuAacNzx6SfRKt\neP6QlEQL+rlhComB6eeGKSQGpp8bZjgkf1SIv/YCIe2u3Ll2x996iZAefSL8lJAg4BVC+t0T\n4QeEBAEvE5KS+EtCggAhQcDrhKQk/tDrhaQn/sALhXR4rpsc+AOvFNLhnVkhkfeCIXV2cHdK\nuJzXhSfxciF1dSd4fd/sLuLdxOH/7RyfxyuG1HZJ5bwbvN4daulZvFRIx91Rmxvvcefz9Qz1\nMZ/d08C9ZEjtlXRxWvTNPFd5a2pwhPSH7tzJnM6avrweYq/VW68V0mlLbGWDfOj6YH0oeDit\nujqfOhwF0kcvFlJ4MV9eLTjW8Ngyby2gNP67uGLqnxcN6eIn+8PLPP9Zlcue6osHiVUtN6YO\nY11/yq6qW68aUnNDfHjPUY4Rlc3p8txx0ZkVPZ81fX64HBzPraTUJSEdD6HuvwD9aadTbj34\nW19dGr/1UJtngFx42ZBOS2pefL5r6V9dWfvNSv12gY19VHo1+NYrh3Q6eT+f4txzatPzTVVM\n/3X79XnshXvhkMqtuxx+XtIAttIBrGKryuZ0Ynncc58fqGe4mLgrqNcN6XBMd73AZwppONcf\n/ugO3lI+hXM9x8W8v1ivFw5p81U1P3rpBrKJXv9gLd//rD1/6jRDufr4J6t4OXHv8+/9xN0D\nlP+8bJtXD+mL1/qJQtr7VMUXF/3Ob0ldX10/fUyt0fkY6tPjP94J7E9vj+t6WObhjYC2zxBf\nPaQvHy7nb8XNvVZ2Pf7ajQw+HdOW29OfZvt2C72ZQeOK6PUZyZeL+c86HH6/q/kuW2k8sf1j\n2hcP6ctRmlcijt/2i08PzM0d0LmuctedGN8cF54mLk5Mznu0e8b4vLM6h9q7b4CQbo/S2Bkd\nL0qctrsBdnTb6Zr/vV9P80Tq3OK3gzykeVXtuzF6QEjfDnO+66c0trt21qHfTqclx3/90TB/\ns9g8IX0/TDOewXxTaZ+QfkZEfEtIECAkCBASBAgJAoQEAUKCACFBgJAgQEgQICQIEBIECAkC\nhAQBQoIAIUGAkCBASBAgJAgQEgQICQKEBAFCggAhQYCQIEBIENBqSB9vk/pPRk9mH48OISR6\nqcWQ1qPGf+xj/OAQQqKXWgxpVqr3ZT21WlRl9tgQQqKXWgypKsvT9LJUjw0hJHqpxZAu/8OL\n3y5FSAyMPRIEtHuOtFjVU86ReDZtXv4eN67ajdaPDSEkeqnd95Fm9ftI1eTN+0g8F3c2QICQ\nIKDVkJaz/WnSaPL+6BBCopfaDOmtcbFh8uAQQqKXWgxpUaarzeZjPNks56OyeGwIIdFLLYY0\nLvUl72V52+b0/S5JSAxMB7cI1Tc1fL5FqDTFB4c/1eotQvUeaV1n4l47nkqrtwiNPzab1aRM\nN+vp9n8eGkJI9FIHtwhV6+3+qFo9NoSQ6KVW30eab1MavW0nqtm3t9oJiaFxZwMECAkChAQB\nQoIAIUFAq3c2/OzmhW+HEBK91GJIcyHxtNo8tFtW3/991Z8MISR6qd1f7Pv+bwf9ZAgh0Uvt\nXmyYN/603WNDCIlectUOAoQEAUKCACFBgJAgQEgQICQIEBIECAkChAQBQoIAIUGAkCBASBAg\nJAgQEgQICQKEBAFCggAhQcDAQtIR/SQkCBASBAgJAoQEAUKCACFBgJAgQEgQICQIEBIECAkC\nhAQBQoIAIUGAkCBASBAgJAgQEgQICQKEBAFCggAhQYCQIEBIECAkCBASBAgJAoQEAUKCACFB\ngJAgQEgQICQIEBIECAkChAQBQoIAIUGAkCBASBAgJAgQEgQICQKEBAFCggAhQYCQIEBIECAk\nCBASBAgJAoQEAUKCACFBgJAgQEgQICQIEBIECAkChAQBQoIAIUGAkCBASBAgJAgQEgQICQKE\nBAFCggAhQYCQIEBIECAkCBASBAgJAoQEAUKCACFBgJAgQEgQICQIEBIECAkChAQBQoIAIUGA\nkCBASBAgJAgQEgQICQKEBAFCgoCBhQT9JCQIEBIECAkChAQBQoIAIUGAkCBASBAgJAgQEgQI\nCQKEBAFCggAhQYCQIEBIECAkCBASBAgJAoQEAUKCgJ6GBAPzwFaeD2cAQ/di/M5XwPh9Xdhg\nhu7F+J2vgPH7urDBDN2L8TtfAeP3dWGDGboX43e+Asbv68IGM3Qvxu98BYzf14UNZuhejN/5\nChi/rwsbzNC9GL/zFTB+Xxc2mKF7MX7nK2D8vi5sMEP3YvzOV8D4fV3YYIbuxfidr4Dx+7qw\nwQzdi/E7XwHj93Vhgxm6F+N3vgLG7+vC4FUJCQKEBAFCggAhQYCQIEBIECAkCBASBAgJAoQE\nAUKCACFBgJAgQEgQICQI6CqkWVWq2br1YefHr7cxfourMh/dGrW1FVhPS5kuN52Nv/NRuhu/\n+Rfy0+N3FNK4/opGbQ+7PP53Bhrjt7gqs3qoat3VClT1SMurQVv9Xqyr/Xegi/GXjZDi43cT\n0keplptlVT7aHXY7Yrkev8VVWZbperdTnHa0ArPdyLMy2XT1AmxN9t+BTsZf1l/65m/G7yak\nWVls//e9vLU66ryMj/v18/gtrspkP/huHTpZgaqsD8N39ALshtl/BzoZf34eIz9+NyFNympz\n8ROiFWW2OYTUGL/9VdmtQ4crUKpNZ+Ovjj/KOhl/XubHyfz43YRUSvNDW5bXA+8+tL4q6zLu\ncgVm9dbU0fjjstqP08n4k7KYlmr2N+O/UkifBu4kpPnuUKKrFdgeWv3RhvQTb+V902lItfGf\njC+klldlVU06XIH5pKpPBjoZvz586jCksu14s653yUKKDtxBSOtq3O0KbKZ/syH9wGh34b/D\nkPbWuyvdzxJS1XFIjfFbXpXxqOMV2G5IVTfjT+vLY/txOvz6rwcNjd9NSPsrJauWr9ptTi9X\nY/xWV2U1Gq86XYGd81XDdscvJ8/49XcT0lv9w2mxP/Ft0yGkxvhtrsqiPtHtbAX27yOtdoc2\nXYzfDKnTr3/yF+N3E1JHdzacQurmjf3VqaMO72xYT3bnSJ3d2bDp8M6G2S6Wdf0G7LPc2bAZ\nnS5Etut4JNwYv71VmZ5/InezAtXNQdv9Xhy+A12Mv95//bM/Gb+jkNb1Hbftj3sMqTF+e6vS\nOLTpZgV29zmP5teDtvu9OHwHOhl//Ydff0chwXMREgQICQKEBAFCggAhQYCQIEBIECAkCBAS\nBAgJAoQEAUKCACFBgJAgQEgQICQIEBIECAkChAQBQoIAIUGAkCBASBAgJAgQEgQICQKEBAFC\nggAhQYCQIEBIECAkCBDSICy6XgH+Q0hDMPJt6jvfoSEovk195zs0BELqPd+hATj8p9BLWY/K\nZPvv+ahU+/84d2NyMS5l7FyqK0IagFNIk1Jmm82k/vd495nz5LyeKvOOV/VlCWkI9od222LW\n2w+L3Yf1uCwuJquy3Gzey6jjNX1ZQhqCY0gfuw+TsstpvTvIa0yW4rCuS0IagmNIh38cXEzO\ntgd+y2Wna/nShDQEPwhp81ZtP1arLlfzlQlpCK5Cunr8aDEbOUfqipCG4CKkyflsaHJ9YuQN\np6544YeglNXmVMl7qZa7y92Ti8lReXfVrkNCGoLR9uznvLsZ16dF9enQefJ9f7L00el6vjAh\nDcHHqBnS7naGMl1dTdZ3NuioK0KCACFBgJAgQEgQICQIEBIECAkChAQBQoIAIUGAkCBASBAg\nJAgQEgQICQKEBAFCggAhQYCQIEBIECAkCBASBAgJAoQEAUKCACFBgJAgQEgQICQIEBIECAkC\n/gHq1auOWZwh8QAAAABJRU5ErkJggg==",
      "text/plain": [
       "Plot with title \"Math_Score_No_Tests.rf\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Yikes... the % Var. explained is alarmingly low... especially when compared to the previous model.\n",
    "# let's see how well the tree number influences the error.\n",
    "plot(Math_Score_No_Tests.rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "10.7897004191127"
      ],
      "text/latex": [
       "10.7897004191127"
      ],
      "text/markdown": [
       "10.7897004191127"
      ],
      "text/plain": [
       "[1] 10.7897"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It appears our tree value is optimized to minimize the error...\n",
    "# Let us calculate the actual RMSE for a prediction on the test set.\n",
    "mean(sqrt((y_test - predict(Math_Score_No_Tests.rf, x_test))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>%IncMSE</th><th scope=col>IncNodePurity</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>gender</th><td>15.95866 </td><td> 3561.884</td></tr>\n",
       "\t<tr><th scope=row>race.ethnicity</th><td>19.92556 </td><td> 7376.719</td></tr>\n",
       "\t<tr><th scope=row>parental.level.of.education</th><td>12.59776 </td><td> 5030.247</td></tr>\n",
       "\t<tr><th scope=row>lunch</th><td>32.51762 </td><td>12858.099</td></tr>\n",
       "\t<tr><th scope=row>test.preparation.course</th><td>24.08750 </td><td> 4910.086</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & \\%IncMSE & IncNodePurity\\\\\n",
       "\\hline\n",
       "\tgender & 15.95866  &  3561.884\\\\\n",
       "\trace.ethnicity & 19.92556  &  7376.719\\\\\n",
       "\tparental.level.of.education & 12.59776  &  5030.247\\\\\n",
       "\tlunch & 32.51762  & 12858.099\\\\\n",
       "\ttest.preparation.course & 24.08750  &  4910.086\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | %IncMSE | IncNodePurity | \n",
       "|---|---|---|---|---|\n",
       "| gender | 15.95866  |  3561.884 | \n",
       "| race.ethnicity | 19.92556  |  7376.719 | \n",
       "| parental.level.of.education | 12.59776  |  5030.247 | \n",
       "| lunch | 32.51762  | 12858.099 | \n",
       "| test.preparation.course | 24.08750  |  4910.086 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "                            %IncMSE  IncNodePurity\n",
       "gender                      15.95866  3561.884    \n",
       "race.ethnicity              19.92556  7376.719    \n",
       "parental.level.of.education 12.59776  5030.247    \n",
       "lunch                       32.51762 12858.099    \n",
       "test.preparation.course     24.08750  4910.086    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Surprisingly, the type of lunch had the largest influence on the predictions of our test set...\n",
    "importance(Math_Score_No_Tests.rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It appears dropping the Reading and Writing score significantly affected the results of this model...\n",
    "# Recommendations: Optimize the current model and visualize the data more appropriately.\n",
    "# It may be more worthwhile to compare which variables most influence the Reading Score and the Writing Score as well.\n",
    "# Then, feature importance can be cross-validated between this model and the Reading and Writing score models...\n",
    "# It may be beneficial to use the score values to predict the parent's level of education in the future..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Do:\n",
    "Data Visualization <br>\n",
    "Display Tree Paths <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
